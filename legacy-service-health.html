<html lang="en">
  <head>
    <meta property="og:title" content="César González Segura - Article title">
    <meta property="og:description" content="Article description">
    <meta property="og:image" content="https://cesargonzalez.dev/photo.webp">
    <meta property="og:url" content="https://cesargonzalez.dev">
    <meta name="description" content="César González Segura Personal - Website">
    <meta charset="utf-8"/>
    <title>César González</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/styles/default.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/styles/atom-one-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="stylesheet" href="./article.css">
  </head>
  <body>
    <header>
      <img src="images/photo.webp" alt="My Picture" />
      <h1>César González Segura</h1>
    </header>

    <div class="contact">
      <a aria-label="Telegram Contact" href="https://t.me/cegonse"><img src="images/telegram.webp" alt="Telegram Logo"></a>
      <a aria-label="LinkedIn Profile" href="https://www.linkedin.com/in/cesar-gonzalez-segura/"><img src="images/linkedin.webp" alt="LinkedIn Logo"></a>
      <a aria-label="Email Contact" href="mailto:contact@cesargonzalez.dev"><img src="images/email.webp" alt="Email Symbol"></a>
      <a aria-label="GitHub Profile" href="https://github.com/cegonse"><img src="images/github.webp" alt="GitHub Logo"></a>
    </div>

    <h2>A workshop to start revamping your team's legacy services</h2>
    <p class="italic">Posted February _th 2026</p>
    <p class="italic">Did you enjoy this article? Follow the conversation on <a>LinkedIn</a> and <a>Blusky</a></p>

    <!--
    the importance of taking care of our legacy
    setting up an example case
    service technical health
    business and product relevance
    evaluating product/technical health matrix
    tracing an action plan
    reflections on the results
    -->
    <article>
      <h2>The importance of taking care of our legacy</h2>
      <p>
        Asd asd asd.
      </p>
    </article>

    <article>
      <h2>Setting up an example case study</h2>
      <p>
        Asd asd asd.
      </p>
      <div class="image fit-20">
        <img src="./images/legacy-article/case-study.png" />
        <span>Asd asdasd.</span>
      </div>
      <p>
        Asd asd asd.
      </p>
    </article>

    <article>
      <h2>Introduction to the workshop</h2>
      <p>
        Asd asd asd.
      </p>
    </article>

    <article>
      <h2>Session #1 - Mapping service health</h2>
      <p>
        This workshop session is designed to help the team reflect about the services they take care of,
        and evaluate their health. A 2~3 hour slot should suffice for this step, but you will have to
        prepare the workshop beforehand.
      </p>
      <p>
        The team will have to describe their services through <b>metrics</b>, helping them measure their
        health. These metrics can be both <b>quantitative</b> or <b>qualitative</b>. Depending on your context,
        some metrics will make more sense than others.
      </p>
      <p>
        I recommend preparing the workshop with someone who has been working with these systems for a long time.
        They will be able to help you define metrics that the team will find easy to relate to when characterizing
        their services.
      </p>
      <p>
        These metrics carry an associated scoring, mapping their health from best case to worst case. In our workshop,
        we used a simple scoring system ranging 1~4, together with a simple semaphoric color code to help us map metrics
        in a digital whiteboard:
        <ul>
          <li><b>1 (<span style="color: rgb(196, 246, 123)">▣</span>) - Ideal</b> &rarr; As good as it can be. Our north-star regarding how we want our services to be.</li>
          <li><b>2 (<span style="color: rgb(252, 164, 0)">▣</span>) - Acceptable</b> &rarr; Rough around its edges, but perfectly manageable for a production service.</li>
          <li><b>3 (<span style="color: rgb(255, 88, 88)">▣</span>) - Problematic</b> &rarr; Problems are becoming worrying, and could get worse if maintenance is not expedited.</li>
          <li><b>4 (<span style="color: rgb(0, 0, 0); -webkit-text-stroke-color: rgb(236, 233, 230); -webkit-text-stroke-width: 0.5px;">▣</span>) - All hope is lost</b> &rarr; A ticking time bomb, we are not ready to react if something unexpected happens.</li>
        </ul>
      </p>
      <p>
        Once these metrics are ready, we'll set-up a service / health matrix in our digital whiteboard to let the team discuss and
        assign a score to each one of our services.
      </p>
      <p>
        Start by creating a matrix with all the services, and one by one, let the team
        decide which score makes more sense for each one of the metrics:
      </p>
      <div class="image fit-20">
        <img src="./images/legacy-article/empty-matrix.png" />
        <span>Start with all your services, and the metrics you have chosen.</span>
      </div>
      <p>
        Then, start a discussion for each of the services and start assigning a score to each metric. As we'll see in the next section,
        some metrics will be objectively measurable, while others will raise a more heated debate.
      </p>
      <p>
        This is by design: we want our team to have a healthy discussion about the services we are managing, and give ourselves some time
        to reflect about our work.
      </p>
      <p>
        Assign a score from 1~4 (green to black, or the color palette of your liking), and finally assign the aggregated score for each of
        them. A simple scoring formula that worked well is <span class="inline-code">ceil(avg([scores]))</span>.
      </p>
      <p>
        This formula pulls scores down, ensuring that scores of services with low ranking metrics get pulled low. This helps to bring attention
        to services that need it.
      </p>
      <p>
        Let's add the scores for the metrics, and calculate the score for each metric:
      </p>
      <div class="image fit-20">
        <img src="./images/legacy-article/filled-matrix.png" />
        <span>All services have been evaluated and assigned a score.</span>
      </div>
      <p>
        With these results, we have a bird's-eye view of the technical state of our teams services, split by each metric. With this framework
        in mind, we will have to define which metrics can be used to measure the health our system.
      </p>
      <p>
        In the next section, you'll find some example metrics that you can use in your own workshop. And later on,
        we'll review the example case study with a set of metrics that could be good candidates for the workshop.
      </p>
    </article>
    <article>
      <h2>Quantitative metrics</h2>
      <p>
        Quantitative metrics are those that can be measured from objective data. These can be
        useful to determine how far are your team's services from the goals set by your organization,
        upcoming regulatory requirements, etc.
      </p>
      <p>
        For each metric, you should define which are the measurable points and/or thresholds to set
        the metric's score. For example, consider a metric with four yes/no questions, where "yes" is
        positive (you want to fulfill all items).
      </p>
      <p>
        In this case, having a "yes" answer to all points would score a 1 (<span style="color: rgb(196, 246, 123)">▣</span>),
        having a "yes" to three out of four would score a 2 (<span style="color: rgb(252, 164, 0)">▣</span>), and so on.
      </p>
      <p>
        Here are some examples you can use as a starting point. Some of these metrics can be answered on a
        yes/no basis, others require gathering actual numbers:
      </p>
      <ul>
        <li>
          <b>Obsevability</b>
            <ul>
              <li>Are our systems observable from the outside?</li>
              <li>Are there alarms in place to notify the team in case there is a production failure?</li>
              <li>Is the team able to understand the current state of the system by checking logs and traces?</li>
              <li>Are performance measurements available for our systems?</li>
            </ul>
        </li>
        <li>
          <b>Security</b>
          <ul>
            <li>Do our systems use libraries or frameworks with known security vulnerabilities?</li>
            <li>Are we running security scanning processes on our systems?</li>
            <li>If so, is the team actively patching found security vulnerabilities?
            <li>Does the team follow security best practices? (masking PII data in logs, properly storing sensitive data and secrets, etc)</li>
          </ul>
        </li>
        <li>
          <b>Up-to-dateness</b>:
          <ul>
            <li>Are any of our systems using frameworks or libraries out of their maintenance window?</li>
            <li>Are any systems using frameworks that could complicate updating to modern versions if needed? (ex. NET Framework, PHP 5...)</li>
            <li>Do our systems comply with all applicable regulations, in all applicable jurisdictions?</li>
          </ul>
        </li>
        <li>
          <b>Scalability</b>
            <ul>
              <li>Is the team aware of how do our services perform under load?</li>
              <li>Does the architecture of the systems allow to scale them up when required?</li>
              <li>Can the team scale them autonomously, or do we need support or permission from other teams?</li>
              <li>Are there auto-scaling measures in place?</li>
              <li>Do we perform regular load testing on our services?</li>
          </ul>
        </li>
        <li>
          <b>Failure Rate</b>
          <ul>
            <li>How often does the service suffer from critical bugs?</li>
            <li>Does the service go down? If so, how long does its recovery take?</li>
            <li>Is the service part of the critical path? Can the business continue operating during downtime?</li>
          </ul>
        </li>
      </ul>
    </article>
    <article>
      <h2>Qualitative metrics</h2>
      <p>
        Qualitative metrics work great to help your team assess how do they "feel" when working with
        their systems. Discussing metrics without factual data to back them might seem counterproductive,
        but in some cases trying to express all problems with hard numbers might complicate the debate.
      </p>
      <p>
        The main point when discussing through these metrics is ensuring there's a healthy debate during the
        workshop, and come to a common understanding of how does it <i>feel</i> to work with these systems.
      </p>
      <p>
        Some qualitative metrics you can use are:
      </p>
      <ul>
        <li>
          <b>Extendability</b>
          <ul>
            <li>How easy is it to add new features to our service?</li>
            <li>Are we held back by its architecture and/or design?</li>
            <li>Do we avoid extending the service beyond surgical changes due to accumulated tech debt?</li>
          </ul>
        </li>
        <li>
          <b>Testing quality</b>
          <ul>
            <li>Are the tests backing our service easy to read and understand?</li>
            <li>Do we trust the results of our tests?</li>
            <li>Is it easy to create new tests?</li>
            <li>Does our test codebase break easily when adding new features?</li>
          </ul>
        </li>
      </ul>
      <p>
        We could find an objective way of measuring these metrics with hard data. But in many
        cases the debate created around these topics is much more valuable to understand the general
        "vibe" around working with these services, than hard numbers by themselves.
      </p>
      <p>
        For example, you could assess testing quality quantitatively by measuring the code base's coverage,
        the number of flaky tests or the time required to execute a full test suite.
      </p>
      <p>
        However, if the architecture supporting these tests makes creating new tests or extending existing
        tests a chore, the team will have an easier time expressing this pain point from a feelings
        point of view. Even though from a numbers perspective, everything seems to be okay.
      </p>
    </article>

    <article>
      <h2>Session #1 - example case study</h2>
      <p>
        Let's go back to our example case study, and define which metrics are most relevant for our services, and how
        to measure them.
      </p>
      <p>
        Our service matrix will consist of the four key services our team manages (excluding off-the-shelf
        components). To measure their health, we will use four metrics, two qualitative and two quantitative:
        <ul>
          <li>
            <b>Extendability</b>: How easy is it to extend the service with new features?
            <ul>
              <li><b>1 (<span style="color: rgb(196, 246, 123)">▣</span>)</b> &rarr; Extending the service with new functionality is seamless. New features and improvements take minimal time.</li>
              <li><b>2 (<span style="color: rgb(252, 164, 0)">▣</span>)</b> &rarr; Adding new functionalities can get cumbersome without refactoring first.</li>
              <li><b>3 (<span style="color: rgb(255, 88, 88)">▣</span>) </b> &rarr; The codebase has grown without regard to its architecture, and adding new features is time consuming and a potential risk.</li>
              <li><b>4 (<span style="color: rgb(0, 0, 0); -webkit-text-stroke-color: rgb(236, 233, 230); -webkit-text-stroke-width: 0.5px;">▣</span>)</b> &rarr; Adding new features is very time consuming, and requires extensive prior clean up through refactoring.</li>
            </ul>
          </li>
          <li>
            <b>Testing Quality</b>: How good are the tests supporting development of the service?
            <ul>
              <li><b>1 (<span style="color: rgb(196, 246, 123)">▣</span>)</b> &rarr; Tests are well maintained, comprehensive and robust. Includes functional and non-functional testing, stress tests, etc...</li>
              <li><b>2 (<span style="color: rgb(252, 164, 0)">▣</span>)</b> &rarr; There is decent test coverage, but their design makes them prone to breaking.</li>
              <li><b>3 (<span style="color: rgb(255, 88, 88)">▣</span>) </b> &rarr; There are some tests, but not coverage isn't good enough to allow changes without risk.</li>
              <li><b>4 (<span style="color: rgb(0, 0, 0); -webkit-text-stroke-color: rgb(236, 233, 230); -webkit-text-stroke-width: 0.5px;">▣</span>)</b> &rarr; There are no tests, and adding new tests would take a lot of effort at this point.</li>
            </ul>
          </li>
          <li>
            <b>Failure Rate</b>: How often does the system fail? How long does it take to recover?
            <ul>
              <li><b>1 (<span style="color: rgb(196, 246, 123)">▣</span>)</b> &rarr; Less than 5 critical failures in a one year period. Upon failure, full recovery took less than 10 minutes.</li>
              <li><b>2 (<span style="color: rgb(252, 164, 0)">▣</span>)</b> &rarr; ~10 critical failures YoY. When these happened, full recovery took less than 10 minutes.</li>
              <li><b>3 (<span style="color: rgb(255, 88, 88)">▣</span>) </b> &rarr; ~10 critical failures YoY. When these happened, full recovery took more than 10 minutes.</li>
              <li><b>4 (<span style="color: rgb(0, 0, 0); -webkit-text-stroke-color: rgb(236, 233, 230); -webkit-text-stroke-width: 0.5px;">▣</span>)</b> &rarr; ~4 critical failures / week. When these happened, full recovery took more than 10 minutes.</li>
            </ul>
          </li>
          <li>
            <b>Security & Up-to-Date</b>: Are its dependencies (including frameworks) up to date? Have security vulnerabilities been detected?
            <ul>
              <li><b>1 (<span style="color: rgb(196, 246, 123)">▣</span>)</b> &rarr; Zero critical security vulnerabilities. Dependencies are updated within 2 weeks after release.</li>
              <li><b>2 (<span style="color: rgb(252, 164, 0)">▣</span>)</b> &rarr; Zero critical security vulnerabilities. Dependencies are updated within 2 weeks after release.</li>
              <li><b>3 (<span style="color: rgb(255, 88, 88)">▣</span>) </b> &rarr; Active critical security vulnerabilities present. Dependencies are updated within 4 weeks after release.</li>
              <li><b>4 (<span style="color: rgb(0, 0, 0); -webkit-text-stroke-color: rgb(236, 233, 230); -webkit-text-stroke-width: 0.5px;">▣</span>)</b> &rarr; Active critical security vulnerabilities present. Dependencies have not been updated for more than 4 weeks.</li>
            </ul>
          </li>
        </ul>
      </p>
      <p>
        Now that we have a set of metrics to measure the health of our teams services, we can build the service / metric health matrix
        and start filling in the score for each metric.
      </p>
      <div class="image fit-20">
        <img src="./images/legacy-article/case-study-empty-matrix.png" />
        <span>Empty service health map.</span>
      </div>
      <p>
        If we have been diligent keeping track of our work in the available tracking tools, deciding the score for the quantitative metrics
        should be straightforward.
      </p>
      <p>
        We can leverage logs, performance metrics, reports from the package manager, security vulnerability analysis tools and post-mortem documentation
        from previous failures and incidents.
      </p>
      <p>
        On the other hand, extendability and testing quality metrics will involve a deeper discussion between the developers in the team. How was the
        experience building the latest features in each service? Was it easy, or did we try to avoid it at all costs?
      </p>
      <div class="image fit-20">
        <img src="./images/legacy-article/case-study-filled-matrix.png" />
        <span>Completed service health map (numerical score added for clarity).</span>
      </div>
      <p>
        After some healthy discussion in the team, metrics for all services have been evaluated and their scores set. The final score has been calculated
        following the formula introduced earlier.
      </p>
      <p>
        Now, we have a birds-eye level picture of the health of our services. From what we've gathered, our <b>web-app</b> and <b>search service</b> are in a good
        enough shape, at an acceptable point for a production app.
      </p>
      <p>
        However, the <b>billing</b> and <b>ratings</b> service are in trouble. Particularly the <b>ratings service</b> has strong ongoing issues, with a very high failure rate, lurking
        security issues and no useful test base to help us overcome these problems.
      </p>
      <p>
        Should we jump in and plan the work to get these services into shape into next iterations? First, we should ask ourselves: <b>is it worth it?</b>
      </p>
    </article>

    <article>
      <h2>Session #2 prep - Considering bussiness importance</h2>
      <p>
        If we only pursued engineering excellence, and were provided with unlimited budget, it would be great to fix all the problems we've found,
        and leave them in perfect condition.
      </p>
      <p>
        In real world software engineering, with limited time, capacity and rapidly switching objectives, we have to compromise.
      </p>
      <p>
        Before even starting to think about how to fix the issues we've found, first we had to understand if it made sense from a business perspective.
      </p>
      <p>
        To do so, we scheduled a short follow-up session with product and business specialists from our team, and listed the product features that are
        backed by our team's services.
      </p>
      <p>
        Then, we sorted all features by <b>business importance</b>, using a numerical scale as we did with the technical services.
      </p>
      <p>
        Ranging from 1 (<span style="color: rgb(196, 246, 123)">▣</span>), meaning a feature that's very important for the business, to
        3 (<span style="color: rgb(255, 88, 88)">▣</span>), meaning it's a nice to have but not really a must have for business continuity.
      </p>
      <p>
        To support this classification, we used a variety of metrics our product experts had in hand. Some of them were:
        <ul>
          <li><b>Usage numbers</b>
            <ul>
              <li>How many users do actively use the feature? (DAU / MAU)</li>
              <li>Are the users making use of the feature important for the business? (paying customers, important contracts...)</li>
            </ul>
          </li>
          <li><b>Revenue Generation</b>
            <ul>
              <li>What is the impact of the feature in terms of revenue, regardless of usage?</li>
              <li>What would happen to revenue if we stopped supporting it?</li>
            </ul>
          </li>
          <li><b>Compliance & Strategical Opportunity</b>
            <ul>
              <li>Is this feature a regulatory requirement in important markets?</li>
              <li>Does supporting it keep key users from leaving the platform?</li>
              <li>Is it a requirement for an important contract with a major customer?</li>
            </ul>
          </li>
        </ul>
      </p>
      <p>
        With the list of features in hand, sorted by their business relevance, we can prepare the next workshop session: matching each
        product feature with its backing service.
      </p>
    </article>

    <article>
      <h2>Session #2 - Evaluating technical / business health</h2>
      <p>
        Asd asd asd.
      </p>
      <div class="image fit-20">
        <img src="./images/legacy-article/business-service-matrix.png" />
        <span>Completed service health map (numerical score added for clarity).</span>
      </div>
      <p>
        Asd asd asd.
      </p>
      <div class="image fit-20">
        <img src="./images/legacy-article/business-service-all-good.png" />
        <span>Completed service health map (numerical score added for clarity).</span>
      </div>
      <p>
        Asd asd asd.
      </p>
      <div class="image fit-20">
        <img src="./images/legacy-article/business-service-danger-zone.png" />
        <span>Completed service health map (numerical score added for clarity).</span>
      </div>
      <p>
        Asd asd asd.
      </p>
      <div class="image fit-20">
        <img src="./images/legacy-article/business-service-reconsider-value.png" />
        <span>Completed service health map (numerical score added for clarity).</span>
      </div>
    </article>

    <article>
      <h2>Session #2 - Example case study</h2>
      <p>
        Asd asd asd.
      </p>
      <div class="image fit-20">
        <img src="./images/legacy-article/business-service-case-study.png" />
        <span>Completed service health map (numerical score added for clarity).</span>
      </div>
    </article>

    <article>
      <h2>Tracing an action plan</h2>
      <p>
        Asd asd asd.
      </p>
    </article>

    <article>
      <h2>Reflecting on the results</h2>
      <p>
        Asd asd asd.
      </p>
    </article>

        <hr />
    <article>
      <p>
        If you've made it this far, thank you <b>so much</b> for reading!
      </p>
      <p>
        If you have any comments, suggestions or want to discuss any of the topics in this article,
        feel free to reach out through any of the channels in the top of the page.
      </p>
    </article>

    <footer><a href="./index.html">Home</a></footer>

    <script>
    hljs.highlightAll();

    const resizeIframes = () => {
      const isPortrait = window.matchMedia("(orientation: portrait)").matches;
      document.querySelectorAll("iframe").forEach((node) => {
        const contentWidth = document.querySelector("header").scrollWidth;
        const targetWidth = isPortrait ?
          contentWidth :
          contentWidth * 0.5;
        const targetHeight = targetWidth * 0.7;

        node.width = targetWidth;
        node.height = targetHeight;
      });
    };

    const makeResourcesClickable = () => {
      document.querySelectorAll("img").forEach((node) => {
        node.addEventListener("click", () => {
          window.open(node.src);
        });
      });
    };

    window.addEventListener("resize", resizeIframes);
    resizeIframes();
    makeResourcesClickable();
    </script>
  </body>
</html>
