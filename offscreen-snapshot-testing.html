<html lang="en">
  <head>
    <meta property="og:title" content="César González Segura - Applying snapshot testing to game development and 3D graphics">
    <meta property="og:description" content="Explore how to combine off-screen rendering and software rendering to build snapshot tests for complex 3D visualizations">
    <meta property="og:image" content="https://cesargonzalez.dev/photo.webp">
    <meta property="og:url" content="https://cesargonzalez.dev">
    <meta name="description" content="César González Segura - Applying snapshot testing to game development and 3D graphics">
    <meta charset="utf-8"/>
    <title>César González</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/styles/default.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/styles/atom-one-dark.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <style>
      html {
        color: rgb(236, 233, 230);
        background-color: #1b2733;
        font-family: system-ui, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
        width: 100%;
      }

      @media (orientation: landscape) {
        body {
          margin-left: 20%;
          margin-right: 20%;
        }
      }

      @media (orientation: portrait) {
        body {
          margin-left: 5%;
          margin-right: 5%;
        }
      }

      header {
        display: flex;
        flex-direction: row;
        align-items: center;
      }

      @media (orientation: landscape) {
        header img {
          height: 2em;
          width: 2em;
          border-radius: 50%;
          margin-right: 1em;
        }
      }

      @media (orientation: portrait) {
        header {
          display: flex;
          flex-direction: column;
          align-items: center;
        }

        header img {
          height: 5em;
          width: 5em;
          border-radius: 50%;
        }
      }

      h2 {
        font-size: 2.5em;
        margin-bottom: 0.1em;
      }

      h3 {
        font-size: 1.5em;
        margin-bottom: 0;
      }

      p {
        text-align: justify;
        font-size: 1.2em;
      }

      li {
        font-size: 1.2em;
        margin-bottom: 0.5em;
      }

      a {
        color: #758CFF;
        text-decoration: underline;
        padding-bottom: 0;
      }

      a:hover {
        color: #4D6AFF;
        text-decoration: underline;
      }

      .image {
        display: flex;
        flex-direction: column;
        align-items: center;

        img {
          border-radius: 8px;
          object-fit: contain;
          width: 100%;
          height: auto;
          margin-top: 1em;
        }

        video {
          border-radius: 8px;
          object-fit: contain;
          width: 100%;
          height: auto;
          margin-top: 1em;
        }

        span {
          margin-top: 1em;
          margin-bottom: 0.5em;
          font-style: italic;
        }
      }

      @media (orientation: landscape) {
        .fit-20 {
          margin-left: 20%;
          margin-right: 20%;
        }
      }

      article > p:first-child {
        margin-top: 2em;
      }

      article > a {
        display: inline-block;
      }

      article > h2 {
        font-size: 2em;
      }

      pre > code {
        border-radius: 8px;
      }

      pre {
        width: 100%;
      }

      iframe + span {
        margin-top: 0.5em;
        margin-bottom: 0.5em;
        font-style: italic;
        text-align: center;
      }

      video {
        border-radius: 8px;
      }

      video + span {
        margin-top: 0.5em;
        margin-bottom: 0.5em;
        font-style: italic;
        text-align: center;
      }

      pre + span {
        margin-bottom: 0.5em;
        font-style: italic;
        font-family: system-ui, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
        text-align: center;
      }

      @media (orientation: landscape) {
        article > pre {
          margin-left: 10%;
          margin-right: 10%;
          margin-top: 2em;
          margin-bottom: 2em;
        }
      }
      @media (orientation: portrait) {
        article > pre {
          margin-top: 2em;
          margin-bottom: 2em;
        }
      }

      article > div {
        display: flex;
        flex-direction: column;
        align-items: center;
      }

      article > div > table {
        text-align: center;
        border-collapse: separate;
        border-spacing: 2em 0;
        font-size: 1.2em;
      }

      table + span {
        font-style: italic;
        margin-top: 1em;
        margin-bottom: 1em;
        text-align: center;
      }

      .italic {
        font-style: italic;
      }

      .contact {
        display: flex;
        flex-direction: row;
      }

      .contact img {
        height: 2em;
        margin-right: 1em;
      }

      .contact a:hover {
        transform: scale(1.05);
        filter: brightness(0.8)
      }

      @media (orientation: portrait) {
        .contact {
          justify-content: space-around;
        }

        .contact img {
          height: 48px;
        }
      }

      footer {
        width: 100%;
        height: 3em;
        display: flex;
        flex-direction: row;
        justify-content: center;
        align-items: center;
        background-color: #263748;
        border-radius: 8px;
        margin-top: 4em;
        margin-bottom: 1em;
      }

      @media (orientation: portrait) {
        footer {
          font-size: 1.5em;
          border-radius: 32px;
        }
      }

      .info {
        background-color: #42586e;
        border-radius: 8px;
        padding: 1em;
        display: block !important;
      }
    </style>
  </head>
  <body>
    <header>
      <img src="images/photo.webp" alt="My Picture" />
      <h1>César González Segura</h1>
    </header>

    <div class="contact">
      <a aria-label="Telegram Contact" href="https://t.me/cegonse"><img src="images/telegram.webp" alt="Telegram Logo"></a>
      <a aria-label="LinkedIn Profile" href="https://www.linkedin.com/in/cesar-gonzalez-segura/"><img src="images/linkedin.webp" alt="LinkedIn Logo"></a>
      <a aria-label="Email Contact" href="mailto:contact@cesargonzalez.dev"><img src="images/email.webp" alt="Email Symbol"></a>
      <a aria-label="GitHub Profile" href="https://github.com/cegonse"><img src="images/github.webp" alt="GitHub Logo"></a>
    </div>

    <h2>Applying snapshot testing to game development</h2>
    <p class="italic">Posted July _th 2025</p>
    <p class="italic">Did you enjoy this article? Follow the conversation on <a>LinkedIn</a></p>
    <article>
      <div class="info">ℹ️ All code used to prepare this article is available in GitHub at <a href="https://github.com/cegonse/offscreen-rendering-tests">cegonse/offscreen-rendering-tests</a></div>
      <p>
        Getting a game to feel, look and play as intended is hard. There's a delicate balance that must be kept in
        check, and any seemingly tiny change could have enormous consequences on how a game feels.
      </p>
      <p>
        Applying testing techniques to games as if they were any software product does not always cut it. There are nuances in
        how a game <i>feels</i> that are hard to capture with unit tests. Systems are so complex and interconnected that it becomes
        really hard to keep track of how changes to shared modules might affect the whole game.
      </p>
      <p>
        Manual testing the whole game everytime a change is done to core mechanics or graphics doesn't cut it except for very small
        games. Playing the game can be automated too, but it still relies on running the whole game which is time consuming and prone
        to breaking.
      </p>
      <p>
        I wanted to explore a lightweight way to test full sub-sets of the game, without having to rely on playing the <i>actual</i> game.
        Can we run small segments of the game and compare the results with stored <i>snapshots</i>, and find out if anything relevant has
        changed?
      </p>
      <p>
        In this article, I've explored how to apply <b>snapshot testing</b> to reduce unintended changes when building games. There are many
        scenarios where snapshot testing can be quite useful, without having to rely on heavy acceptance tests. But it also comes with a great
        number of caveats, so it won't be applicable in all cases.
      </p>
    </article>
    <article>
      <h2>Testing and game development</h2>
      <p>
        Since I first started learning about software automated testing, I began thinking about how could it be
        effectively applied to game development. If you have ever developed a videogame, you will have experienced
        first-hand how complex game development can be.
      </p>
      <p>
        Funnily enough, the environment where I've seen less automated testing through my career is game development.
        I've mostly worked on small games, with one exception (what the industry calls
        <a href="https://en.wikipedia.org/wiki/AAA_(video_game_industry)#III"><i>Triple-I</i></a> games),
        so probably I've missed out on how big studios handle testing.
      </p>
      <p>
        Reading from sites like <a href="https://www.gamedeveloper.com/">GameDeveloper</a> and remembering conversations with
        people working on established studios, I learned that many rely on automated QA tests based on macros. These tests
        auto-play portions of the game from recorded controller inputs and bespoke markers detect whether a goal has been reached
        or not.
      </p>
      <p>
        This method however requires launching the full game, and as with all QA acceptance tests, are costly to implement, prone
        to breaking upon change, costly to maintain once working, and require powerful hardware to run (as powerful as the hardware
        required to run the game itself).
      </p>
      <p>
        QA acceptance tests are necessary and must always be present in any product's testing pyramid. But, how can we reduce the
        cost (both building, maintaining and running) of these tests?
      </p>
      <p>
        What about running smaller integration tests of only a subset of the full game? And if possible, avoiding running it on
        retail hardware? For example, directly in GitHub Actions CI runners.
      </p>
      <div>
        <iframe width="auto" height="auto" src="https://www.youtube.com/embed/CgMV2dFFdFE" title="Factorio: Space Age - Graphics mode tests" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        <span><a href="https://store.steampowered.com/app/427520/Factorio">Factorio's</a> testing mode resembles what I wanted to achieve</span>
      </div>
    </article>

    <article>
      <h2>Laying out the concepts</h2>
      <p>Asd</p>
    </article>

    <article>
      <h2>Shader and scene snapshot tests</h2>
      <div class="info">ℹ️ Find code for shader testing at the <a href="https://github.com/cegonse/offscreen-rendering-tests/tree/main/testing-shaders">testing-shaders</a> directory</div>
      <p>
        Shaders are difficult to build and get right. Depending on the models themselves, desired effects, and how
        it can be hard to combine them with each other. Also, many times the artistic intent we want to convey through
        shaders is achieved by combining many shaders, applying to different meshes, full-screen shaders and others.
      </p>
      <p>
        There are options to unit test shaders like <a href="https://github.com/cezbloch/shaderator">Shaderator by Cezary Bloch</a>,
        and although tools like this are perfect to iteratively build complex kernels such as compute shaders or
        complex visual shaders, it might not be the best fit when the important outcome is the visual cohesion of the scene,
        rather than the calculations done by the shader.
      </p>
      <p>
        Also, many times shaders might are built in visual scripting and node-based tools, which in turn generate
        source code that can be used by game engines. In these cases, unit testing wouldn't be easy or maybe possible at all.
      </p>
      <p>
        Snapshot testing looks like a great fit for this scenario. Let's lay out how could it be carried out.
      </p>
      <p>
        Let's try to replicate what would be done when building a complete scene with different meshes, particle effects,
        full screen shaders to do tone-mapping, lens correction, and so on.
      </p>
      <p>
        In this case, technical artists would tweak all the parameters as desired until getting it right.
        Storing a snapshot of the scene and testing it in the CI would help ensure the scene hasn't been unwillingly changed,
        for example when re-using the same shaders in another scene and tweaking them for it.
      </p>
      <p>
        I will keep the focus on the test code. Shaders themselves are example shaders available from Raylib, <a href="https://github.com/raysan5/raylib/blob/master/examples/shaders/resources/shaders/glsl330/bloom.fs">bloom</a> and <a href="https://github.com/raysan5/raylib/blob/master/examples/shaders/resources/shaders/glsl330/grayscale.fs">grayscale</a>
        full screen shaders.
      </p>
      <div>
        <pre><code>#include &lt;cest&gt;
#include &lt;render.h&gt;
#include &lt;verify.h&gt;

describe("Post-processing Camera Shaders", []() {
  it("renders all pixels with bloom effect", []() {
    RenderWithShader("common/bloom.fs");
    Verify();
  });

  it("renders all pixels in B&W", []() {
    RenderWithShader("common/grayscale.fs");
    Verify();
  });

  afterEach([]() {
    CleanUp();
  });
});
        </code></pre>
      </div>
      <p>
        Tests are very simple, and in fact, it could be simplified even further by parametrizing the shader location. The two main parts are:
      </p>
      <ul>
        <li><b>Rendering</b> → Renders the scene with a sample mesh and applying the full-screen shader passed as an argument.</li>
        <li><b>Verifying</b> → Compares the rendered image with the stored snapshot, and throws an assertion error when the images are different, causing the test to fail.</li>
      </ul>
      <p>
        The interesting part lies in the <b>verification</b> part of the test. The steps it takes to check the currently rendered image against
        the snapshot are, roughly (if interested, check the details in GitHub)
      </p>
      <ul>
        <li>Take a screenshot of the current image. This will be the generated image to compare against the snapshot.</li>
        <li>If an snapshot image does not exist, create one. This will only be the case the <b>first time</b> the test is run. In this first execution, the
        snapshot would be committed as the reference for next runs.</li>
        <li>Compare the current image to the generated image. In this test, ImageMagick's MagickWand API was used to calculate the difference between
          both images.
        </li>
        <li>If the current image is different from the snapshot, it means the scene has been modified → fail the test. For convenience, store the snapshot
          result so it can be reviewed later. Imgur API can be used to upload images and videos very easily (if privacy isn't a concern!).
        </li>
      </ul>
      <p>
        Take this example where the grayscale shader has been purposely modified to look like an unintended change. Instead of rendering a black and white image,
        it tints the result with a blue hue. As expected, the test fails since the rendering differs from the snapshot, and we get back the link to the result
        in the CI test execution:
      </p>
      <div class="image fit-20">
        <img src="./images/offscreen-article/shader-output.png" />
      </div>
      <p>
        And when checking the results, both the expected result and the actual result can be compared side by side, giving quick feedback of what has gone wrong.
      </p>
      <div class="image fit-20">
        <img src="./images/offscreen-article/shader-image.png" />
      </div>
      <p>
        Without applying snapshot testing, the most probable way this unintended change would have been discovered would have been when trying out the game.
        Perhaps by sheer coincidence, when another feature was being tested out and someone noticed the change and raised the bug. Depending on the nature of
        the change, it might would not have been ever noticed, and released in the final product.
      </p>
      <p>
        It must be noted that this example scene is extremely simple and does not take into account variability in the rendered image, such as shaders changing
        with time or other inputs. Also, it assumes rendering is deterministic, otherwise every render would be slightly different when compared to the snapshot,
        making the comparison impossible.
      </p>
      <p>
        In any case, I'm quite sure this can be quite valuable when testing out shaders. Maybe testing full scenes is not feasible as complexity increases,
        but avoiding introducing changes to shaders by mistake already feels like a big improvement.
      </p>
    </article>

    <article>
      <h2>Game snapshot tests</h2>
      <p>
        Asd
      </p>
      <div class="image fit-20">
        <video src="./images/offscreen-article/video_game.mp4" autoplay loop controls></video>
        <span>Simple enough but it will let us put the concepts to test</span>
      </div>
      <p>
        Asd
      </p>
      <div>
        <pre><code>#include &lt;cest&gt;
#include &lt;game.h&gt;
#include &lt;platform-test.h&gt;
#include &lt;test-helper.h&gt;

describe("JumpingGame", []() {
  it("builds up to 2 points after traversing several columns", []() {
    auto headless_mode = true;
    Game game(headless_mode);

    onEveryNthFrame(6, [](int _) { Platform::ForceJumpKey(); });
    onEveryNthFrame(HEADLESS_MODE_FRAMESKIP, [](int frame) { Screenshot(frame); });
    runFrames(NUM_FRAMES_TO_RENDER, [&]() { game.DoFrame(); });

    auto assertion = [&]() { expect(game.Score()).toBeGreaterThan(2); };
    Verify(assertion);
  });
});
        </code></pre>
        <span>We'll review the parts of the game's acceptance test next</span>
      </div>
      <p>
        Asd asd asd asd asd asd
      </p>
      <div class="image fit-20">
        <video src="./images/offscreen-article/video_1.mp4" autoplay loop controls></video>
        <span>The end result pulled right from the CI pipeline</span>
      </div>
    </article>

    <article>
      <h2>Closing thoughts</h2>
      <p>
        Asd
      </p>
      <p>
        What is it useful for
      </p>
      <ul>
        <li>Asd</li>
        <li>Asd</li>
        <li>Asd</li>
      </ul>
      <p>What are the main challenges</p>
      <ul>
        <li>Asd</li>
        <li>Asd</li>
        <li>Asd</li>
      </ul>
      <p>
        What is not going to work
      </p>
      <ul>
        <li>Asd</li>
        <li>Asd</li>
        <li>Asd</li>
      </ul>
    </article>

    <footer><a href="./index.html">Home</a></footer>

    <script>
    hljs.highlightAll();

    const resizeIframes = () => {
      const isPortrait = window.matchMedia("(orientation: portrait)").matches;
      document.querySelectorAll("iframe").forEach((node) => {
        const contentWidth = document.querySelector("header").scrollWidth;
        const targetWidth = isPortrait ?
          contentWidth :
          contentWidth * 0.5;
        const targetHeight = targetWidth * 0.7;

        node.width = targetWidth;
        node.height = targetHeight;
      });
    };

    window.addEventListener("resize", resizeIframes);
    resizeIframes();
    </script>
  </body>
</html>
